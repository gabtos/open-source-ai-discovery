{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa14ca88",
   "metadata": {},
   "source": [
    "# Set Up\n",
    "Run `pip --install hugging_face_hub` if needed\n",
    "\n",
    "## Usage\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Search Hugging Face models for a phrase (default: \"open source\"),\n",
    "gather metadata + README text, and save to CSV.\n",
    "\n",
    "Usage:\n",
    "  python hf_search_models.py --query \"open source\" --limit 200 --out models_open_source.csv\n",
    "\n",
    "Optional:\n",
    "  export HF_TOKEN=hf_xxx   # if you want to include private models or higher rate limits\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3c3ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Imports and helpers\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from huggingface_hub import HfApi, model_info, hf_hub_download\n",
    "from huggingface_hub.utils import HfHubHTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d60b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "try:\n",
    "    import yaml  # pip install pyyaml\n",
    "except Exception:\n",
    "    yaml = None\n",
    "\n",
    "def _normalize_license(val):\n",
    "    \"\"\"Return a clean license string from various shapes.\"\"\"\n",
    "    if val is None:\n",
    "        return \"\"\n",
    "    if isinstance(val, str):\n",
    "        return val.strip()\n",
    "    if isinstance(val, (list, tuple)):\n",
    "        uniq = [str(s).strip() for s in val if s and str(s).strip()]\n",
    "        return \", \".join(sorted(set(uniq)))\n",
    "    if isinstance(val, dict):\n",
    "        for k in (\"id\", \"name\", \"license\", \"value\"):\n",
    "            if k in val and val[k]:\n",
    "                return str(val[k]).strip()\n",
    "        try:\n",
    "            import json\n",
    "            return json.dumps(val, ensure_ascii=False)\n",
    "        except Exception:\n",
    "            return str(val)\n",
    "    return str(val).strip()\n",
    "\n",
    "def _parse_yaml_front_matter(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse YAML front-matter from README markdown text.\n",
    "    Supports:\n",
    "      ---\\n<yaml>\\n---   or\n",
    "      ---\\n<yaml>\\n...\n",
    "    Returns {} if not found or parse fails.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return {}\n",
    "    # Match front matter at the very top of the file\n",
    "    m = re.match(r\"^\\s*---\\s*\\n(.*?)\\n(?:---|\\.\\.\\.)\\s*(?:\\n|$)\", text, re.DOTALL)\n",
    "    if not m:\n",
    "        return {}\n",
    "    yaml_block = m.group(1)\n",
    "    # Prefer PyYAML if present\n",
    "    if yaml is not None:\n",
    "        try:\n",
    "            data = yaml.safe_load(yaml_block) or {}\n",
    "            if isinstance(data, dict):\n",
    "                return data\n",
    "            return {}\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Minimal fallback: parse simple key: value and lists with \"- item\"\n",
    "    data = {}\n",
    "    current_key = None\n",
    "    for line in yaml_block.splitlines():\n",
    "        if re.match(r\"^\\s*#\", line) or not line.strip():\n",
    "            continue\n",
    "        kv = re.match(r\"^([A-Za-z0-9_\\-]+)\\s*:\\s*(.*)$\", line)\n",
    "        if kv:\n",
    "            key, value = kv.group(1), kv.group(2).strip()\n",
    "            if value == \"\" or value == \"|\":\n",
    "                data[key] = []\n",
    "                current_key = key\n",
    "            elif value.startswith(\"[\") and value.endswith(\"]\"):\n",
    "                # simple inline list: [a, b]\n",
    "                items = [s.strip() for s in value[1:-1].split(\",\") if s.strip()]\n",
    "                data[key] = items\n",
    "                current_key = None\n",
    "            else:\n",
    "                data[key] = value\n",
    "                current_key = None\n",
    "            continue\n",
    "        # list item\n",
    "        if current_key and re.match(r\"^\\s*-\\s+\", line):\n",
    "            item = re.sub(r\"^\\s*-\\s+\", \"\", line).strip()\n",
    "            data.setdefault(current_key, [])\n",
    "            data[current_key].append(item)\n",
    "    return data\n",
    "\n",
    "def resolve_license(info, fallback_tags=None, readme_text: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    Resolve license using multiple sources, in order:\n",
    "      1) info.cardData (license, licenses, license_name, license_id)\n",
    "      2) info.config.license\n",
    "      3) tags entries like 'license:apache-2.0'\n",
    "      4) README YAML front-matter keys: license, licenses, license_name, license_id\n",
    "      5) presence of LICENSE file (returns 'license-file' if found)\n",
    "    Also returns an optional license_link if present in YAML (e.g., 'license_link').\n",
    "    \"\"\"\n",
    "    # 1) cardData\n",
    "    cd = getattr(info, \"cardData\", None)\n",
    "    if isinstance(cd, dict):\n",
    "        for key in (\"license\", \"licenses\", \"license_name\", \"license_id\"):\n",
    "            if key in cd and cd[key]:\n",
    "                lic = _normalize_license(cd[key])\n",
    "                if lic:\n",
    "                    return lic, cd.get(\"license_link\", \"\")\n",
    "\n",
    "    # 2) config\n",
    "    cfg = getattr(info, \"config\", None)\n",
    "    if isinstance(cfg, dict) and cfg.get(\"license\"):\n",
    "        lic = _normalize_license(cfg[\"license\"])\n",
    "        if lic:\n",
    "            return lic, \"\"\n",
    "\n",
    "    # 3) tags (handles the common 'license:apache-2.0' pattern)\n",
    "    tags = fallback_tags or getattr(info, \"tags\", None)\n",
    "    if tags:\n",
    "        for t in tags:\n",
    "            if isinstance(t, str) and t.lower().startswith(\"license:\"):\n",
    "                lic = t.split(\":\", 1)[1].strip()\n",
    "                if lic:\n",
    "                    return lic, \"\"\n",
    "\n",
    "    # 4) README YAML front-matter\n",
    "    if readme_text:\n",
    "        meta = _parse_yaml_front_matter(readme_text)\n",
    "        if meta:\n",
    "            for key in (\"license\", \"licenses\", \"license_name\", \"license_id\"):\n",
    "                if key in meta and meta[key]:\n",
    "                    lic = _normalize_license(meta[key])\n",
    "                    link = _normalize_license(meta.get(\"license_link\", \"\"))\n",
    "                    if lic:\n",
    "                        return lic, link\n",
    "\n",
    "    # 5) LICENSE file present?\n",
    "    try:\n",
    "        siblings = getattr(info, \"siblings\", None) or []\n",
    "        has_license_file = any(\n",
    "            hasattr(s, \"rfilename\") and s.rfilename.upper() == \"LICENSE\" for s in siblings\n",
    "        )\n",
    "        if has_license_file:\n",
    "            return \"license-file\", \"\"\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return \"\", \"\"  # unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b56e8",
   "metadata": {},
   "source": [
    "# Hugging Face model search in a Jupyter notebook\n",
    "# - No argparse; configure via variables below\n",
    "# - No default limit (LIMIT=None)\n",
    "# - Optional README download for NLP\n",
    "# - Saves results to CSV and shows a preview as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10f515eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for models matching: 'open source' (limit=None)\n",
      "Collected 68 models.\n",
      "Wrote 68 rows to hf_models.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>author</th>\n",
       "      <th>type_pipeline_tag</th>\n",
       "      <th>library_name</th>\n",
       "      <th>license</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>private</th>\n",
       "      <th>gated</th>\n",
       "      <th>readme_snippet</th>\n",
       "      <th>readme_text</th>\n",
       "      <th>card_data_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jd-opensource/JSL-joysafety-v1</td>\n",
       "      <td>jd-opensource</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(, )</td>\n",
       "      <td>2025-09-23T07:51:20+00:00</td>\n",
       "      <td>2025-09-24T15:07:49+00:00</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>opensourcerelease/DeepSeek-V3-bf16</td>\n",
       "      <td>opensourcerelease</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(, )</td>\n",
       "      <td>2024-12-26T16:07:44+00:00</td>\n",
       "      <td>2024-12-30T08:37:05+00:00</td>\n",
       "      <td>45958</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>opensource/extract_names</td>\n",
       "      <td>opensource</td>\n",
       "      <td>token-classification</td>\n",
       "      <td>transformers</td>\n",
       "      <td>(apache-2.0, )</td>\n",
       "      <td>2022-03-02T23:29:05+00:00</td>\n",
       "      <td>2021-01-19T04:59:04+00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OpenSourceMentorShip/gpt4all</td>\n",
       "      <td>OpenSourceMentorShip</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(, )</td>\n",
       "      <td>2023-04-17T14:21:29+00:00</td>\n",
       "      <td>2023-04-17T14:33:12+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haoliu/coh_llama_on_open_source_data</td>\n",
       "      <td>haoliu</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(, )</td>\n",
       "      <td>2023-08-26T19:14:12+00:00</td>\n",
       "      <td>2023-09-14T07:24:10+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Opensourced/wormgpt-24</td>\n",
       "      <td>Opensourced</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(apache-2.0, )</td>\n",
       "      <td>2024-02-07T04:21:04+00:00</td>\n",
       "      <td>2024-02-07T04:31:50+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mixtralyanis/bart_opensource</td>\n",
       "      <td>mixtralyanis</td>\n",
       "      <td></td>\n",
       "      <td>transformers</td>\n",
       "      <td>(mit, )</td>\n",
       "      <td>2024-02-25T18:02:34+00:00</td>\n",
       "      <td>2024-02-25T18:50:38+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mixtralyanis/flant5-opensource</td>\n",
       "      <td>mixtralyanis</td>\n",
       "      <td></td>\n",
       "      <td>transformers</td>\n",
       "      <td>(apache-2.0, )</td>\n",
       "      <td>2024-02-27T16:12:16+00:00</td>\n",
       "      <td>2024-02-27T16:15:21+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mixtralyanis/flant5-opensource-and-tuned</td>\n",
       "      <td>mixtralyanis</td>\n",
       "      <td></td>\n",
       "      <td>transformers</td>\n",
       "      <td>(, )</td>\n",
       "      <td>2024-02-27T16:20:33+00:00</td>\n",
       "      <td>2024-02-27T16:24:59+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mrdas/open-source</td>\n",
       "      <td>mrdas</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(, )</td>\n",
       "      <td>2024-02-29T13:29:58+00:00</td>\n",
       "      <td>2024-02-29T13:29:58+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   model_id                author  \\\n",
       "0            jd-opensource/JSL-joysafety-v1         jd-opensource   \n",
       "1        opensourcerelease/DeepSeek-V3-bf16     opensourcerelease   \n",
       "2                  opensource/extract_names            opensource   \n",
       "3              OpenSourceMentorShip/gpt4all  OpenSourceMentorShip   \n",
       "4      haoliu/coh_llama_on_open_source_data                haoliu   \n",
       "5                    Opensourced/wormgpt-24           Opensourced   \n",
       "6              mixtralyanis/bart_opensource          mixtralyanis   \n",
       "7            mixtralyanis/flant5-opensource          mixtralyanis   \n",
       "8  mixtralyanis/flant5-opensource-and-tuned          mixtralyanis   \n",
       "9                         mrdas/open-source                 mrdas   \n",
       "\n",
       "      type_pipeline_tag  library_name         license  \\\n",
       "0                                                (, )   \n",
       "1                                                (, )   \n",
       "2  token-classification  transformers  (apache-2.0, )   \n",
       "3                                                (, )   \n",
       "4                                                (, )   \n",
       "5                                      (apache-2.0, )   \n",
       "6                        transformers         (mit, )   \n",
       "7                        transformers  (apache-2.0, )   \n",
       "8                        transformers            (, )   \n",
       "9                                                (, )   \n",
       "\n",
       "                  created_at              last_modified  downloads  likes  \\\n",
       "0  2025-09-23T07:51:20+00:00  2025-09-24T15:07:49+00:00         29      6   \n",
       "1  2024-12-26T16:07:44+00:00  2024-12-30T08:37:05+00:00      45958     31   \n",
       "2  2022-03-02T23:29:05+00:00  2021-01-19T04:59:04+00:00         12      7   \n",
       "3  2023-04-17T14:21:29+00:00  2023-04-17T14:33:12+00:00          0      0   \n",
       "4  2023-08-26T19:14:12+00:00  2023-09-14T07:24:10+00:00          0      0   \n",
       "5  2024-02-07T04:21:04+00:00  2024-02-07T04:31:50+00:00          0     14   \n",
       "6  2024-02-25T18:02:34+00:00  2024-02-25T18:50:38+00:00          2      0   \n",
       "7  2024-02-27T16:12:16+00:00  2024-02-27T16:15:21+00:00          3      0   \n",
       "8  2024-02-27T16:20:33+00:00  2024-02-27T16:24:59+00:00          2      0   \n",
       "9  2024-02-29T13:29:58+00:00  2024-02-29T13:29:58+00:00          0      0   \n",
       "\n",
       "   private  gated readme_snippet readme_text card_data_json  \n",
       "0    False  False                                            \n",
       "1    False  False                                            \n",
       "2    False  False                                            \n",
       "3    False  False                                            \n",
       "4    False  False                                            \n",
       "5    False  False                                            \n",
       "6    False  False                                            \n",
       "7    False  False                                            \n",
       "8    False  False                                            \n",
       "9    False  False                                            "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from huggingface_hub import HfApi, model_info, hf_hub_download\n",
    "# from huggingface_hub.utils import HfHubHTTPError\n",
    "\n",
    "\n",
    "def safe_str(x: Optional[str]) -> str:\n",
    "    return \"\" if x is None else str(x)\n",
    "\n",
    "def read_readme_text(repo_id: str) -> str:\n",
    "    \"\"\"Download README.md for a repo and return its text. Returns '' if missing.\"\"\"\n",
    "    try:\n",
    "        readme_path = hf_hub_download(repo_id=repo_id, filename=\"README.md\", repo_type=\"model\")\n",
    "        with open(readme_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "            return f.read()\n",
    "    except HfHubHTTPError:\n",
    "        return \"\"\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "def get_license(info):\n",
    "    # First try cardData (most common place)\n",
    "    if info.cardData and \"license\" in info.cardData:\n",
    "        return info.cardData[\"license\"]\n",
    "    # Then try config\n",
    "    if info.config and \"license\" in info.config:\n",
    "        return info.config[\"license\"]\n",
    "    return \"unknown\"\n",
    "\n",
    "def iso_or_blank(dt) -> str:\n",
    "    \"\"\"Format datetime to ISO 8601 or return blank.\"\"\"\n",
    "    try:\n",
    "        if dt is None:\n",
    "            return \"\"\n",
    "        if isinstance(dt, str):\n",
    "            return dt\n",
    "        return dt.isoformat()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "# %% Configuration\n",
    "QUERY = \"open source\"          # search phrase\n",
    "LIMIT = None                   # None means no limit; set an int to cap results\n",
    "OUT_CSV = \"hf_models.csv\"      # output CSV path\n",
    "SLEEP = 0.2                    # seconds to sleep between requests to be polite\n",
    "INCLUDE_README = False         # set True to include full README text\n",
    "README_SNIPPET_CHARS = 0       # set >0 to include a short snippet\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\", None)  # or set a string token here\n",
    "\n",
    "# %% Search and collect\n",
    "api = HfApi(token=HF_TOKEN)\n",
    "\n",
    "print(f\"Searching for models matching: {QUERY!r} (limit={LIMIT})\")\n",
    "if LIMIT is not None:\n",
    "    models_iter = api.list_models(search=QUERY, full=True, direction=-1, limit=LIMIT)\n",
    "else:\n",
    "    # omit limit for no cap\n",
    "    models_iter = api.list_models(search=QUERY, full=True, direction=-1)\n",
    "\n",
    "rows = []\n",
    "count = 0\n",
    "\n",
    "for m in models_iter:\n",
    "    repo_id = m.modelId  # e.g., \"bert-base-uncased\"\n",
    "    try:\n",
    "        info = model_info(repo_id, token=HF_TOKEN)\n",
    "    except HfHubHTTPError as e:\n",
    "        print(f\"Skipping {repo_id}: {e}\")\n",
    "        time.sleep(SLEEP)\n",
    "        continue\n",
    "\n",
    "    # Extract metadata\n",
    "    model_name = info.modelId\n",
    "    author = getattr(info, \"author\", \"\") or (model_name.split(\"/\")[0] if \"/\" in model_name else \"\")\n",
    "    pipeline_tag = getattr(info, \"pipeline_tag\", None)\n",
    "    library_name = getattr(info, \"library_name\", None)\n",
    "    # license_name = getattr(info, \"license\", None)\n",
    "    license_name = resolve_license(info)\n",
    "    created_at = iso_or_blank(getattr(info, \"created_at\", None))\n",
    "    last_modified = iso_or_blank(getattr(info, \"lastModified\", None))\n",
    "    downloads = getattr(info, \"downloads\", None)\n",
    "    likes = getattr(info, \"likes\", None)\n",
    "    private = getattr(info, \"private\", None)\n",
    "    gated = getattr(info, \"gated\", None)\n",
    "\n",
    "    # README / model card text\n",
    "    if INCLUDE_README or README_SNIPPET_CHARS > 0:\n",
    "        readme_text = read_readme_text(repo_id)\n",
    "        readme_snippet = readme_text[: README_SNIPPET_CHARS] if README_SNIPPET_CHARS > 0 else \"\"\n",
    "    else:\n",
    "        readme_text = \"\"\n",
    "        readme_snippet = \"\"\n",
    "\n",
    "    # cardData is parsed front matter from the model card\n",
    "    card_data = getattr(info, \"cardData\", None)\n",
    "    try:\n",
    "        import json\n",
    "        card_data_json = json.dumps(card_data, ensure_ascii=False) if card_data is not None else \"\"\n",
    "    except Exception:\n",
    "        card_data_json = \"\"\n",
    "\n",
    "    row = {\n",
    "        \"model_id\": model_name,\n",
    "        \"author\": author,\n",
    "        \"type_pipeline_tag\": safe_str(pipeline_tag),\n",
    "        \"library_name\": safe_str(library_name),\n",
    "        \"license\": license_name,\n",
    "        \"created_at\": created_at,\n",
    "        \"last_modified\": last_modified,\n",
    "        \"downloads\": downloads if downloads is not None else \"\",\n",
    "        \"likes\": likes if likes is not None else \"\",\n",
    "        \"private\": private if private is not None else \"\",\n",
    "        \"gated\": gated if gated is not None else \"\",\n",
    "        \"readme_snippet\": readme_snippet,\n",
    "        \"readme_text\": readme_text if INCLUDE_README else \"\",\n",
    "        \"card_data_json\": card_data_json,\n",
    "    }\n",
    "    rows.append(row)\n",
    "    count += 1\n",
    "\n",
    "    # polite pacing to reduce throttling risk\n",
    "    time.sleep(SLEEP)\n",
    "\n",
    "print(f\"Collected {len(rows)} models.\")\n",
    "\n",
    "# %% Save to CSV and preview\n",
    "fieldnames = [\n",
    "    \"model_id\",\n",
    "    \"author\",\n",
    "    \"type_pipeline_tag\",\n",
    "    \"library_name\",\n",
    "    \"license\",\n",
    "    \"created_at\",\n",
    "    \"last_modified\",\n",
    "    \"downloads\",\n",
    "    \"likes\",\n",
    "    \"private\",\n",
    "    \"gated\",\n",
    "    \"readme_snippet\",\n",
    "    \"readme_text\",\n",
    "    \"card_data_json\",\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(rows, columns=fieldnames)\n",
    "df.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
    "print(f\"Wrote {len(df)} rows to {OUT_CSV}\")\n",
    "\n",
    "# Show a quick preview\n",
    "df.head(10)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
