---
title: "The State of \"Open\" Source AI"
subtitle: "Exploring Data on AI Model Releases"
author:
  - name: Gabriel Toscano
    orcid: 0009-0005-0673-9708
    email: first_name.last_name@duke.edu
    affiliations:
      - name: Duke University Sanford School of Public Policy
output-file: "index.html"
format:
  html:
    smooth-scroll: false
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: true
    code-summary: "Click to show code"
    embed-resources: true
    theme:
      light: yeti
     
---

## 1.0 Executive Summary
Founded in 1998, the [Open Source Initiative (OSI)](https://opensource.org/) is a global nonprofit that advances Open Source software through advocacy, policy research, and engagement across developers, corporations, nonprofits, and governments. The OSI maintains the Open Source Definition (OSD) and, more recently, released the 1.0 Open Source AI Definition (OSAID). Through these definitions, the OSI seeks to ensure that digital systems can be freely accessed, used, modified, and shared by anyone, upholding the four core freedoms of Open Source philosophy. 

The availability and flexibility of Open Source software makes it an attractive, and in some contexts crucial, mechanism for building digital tools within industry and government. Open Source Software (OSS) underpins critical infrastructure and consumer technologies, from electric grids to medical software and smartphone apps. Today, OSS contributes tens of billions in economic output in the U.S. and more than $8 trillion globally. The value derived is expected to grow as Open Source AI is adopted across public and private sectors. 

The October 2024 release of the [Open Source AI Definition (OSAID)](https://opensource.org/ai/open-source-ai-definition) sought to anchor the term *Open Source AI* using clear, unambiguous standards. Yet, openness in AI is nascent and inconsistently understood. 

This project uses AI model metadata from [Hugging Face](https://huggingface.co/) to understand how "open" AI models are deployed. The goal is to uncover patterns in how the concept of "open" AI is used in practice. 


::: {.callout-tip title="Why now?"}
The AI boom, driven by unprecedented investment and access to tools, has spawned a flood of models claiming to be open. 
:::

### 1.1 Goals
- Understand how “open” AI models are being released 
- Analyze key trends in “open” AI model releases

**Not**

- Evaluate models for “openness” 
- Evaluate the Open Source AI Definition (OSAID 1.0)

### 1.2 Data Gathering
Hugging Face is the most widely-used platform for AI models with over 200,000 models hosted on the repository. It allows people to share and use AI models and related datasets. 

This study uses AI model metadata downloaded through the Hugging Face [Hub API](https://huggingface.co/docs/hub/api). Metadata includes `model name`,`author`, `release date`, `license`, and `last modified date`, `base-model`, and `downloads`. 

Two searches where performed

- **Full-text-search (N = 20,069):** searching for any models where the model name or metadata includes the word "open"
- **Author search (N=2,028):** searching for AI models released by prominent AI labs (Alibaba, Deepseek, Google, Meta, Microsoft, Mistral, XAI, Open AI) 

### 1.3 Key Findings
Preliminary exploratory analysis of the Hugging Face data points to differing practices in how developers signal openness in AI. These results illustrate some consistency with the OSAID as well as friction surrounding licensing practices. 

- The overwhelming majority of “open” models are based on larger models
- Apache 2.0 is the most popular OSI-approved license, followed by MIT
- CC-by licenses are prevalent, despite Creative Commons’ recommendations against using CC licenses for software
- The vast majority, over 50% of all models in in this sample, are released with an “unknown license” 
- Alibaba’s Qwen family of models are the most popular base model in this sample
- Custom licenses like Qwen, Llama, Gemma, Grok, OpenRAIL are becoming increasingly common, specially for flagship models, yet impose usage restrictions

### 1.4 Presentation
Preliminary study findings where presented at the [All Things Open Conference](https://2025.allthingsopen.org/) hosted in Raleigh, NC, USA in October, 2025

[Presentation video](https://opensource.org/blog/state-of-the-source-at-ato-2025-state-of-the-open-ai)

```{=html}
    <iframe
    src="report_files/pdf_presentation/State_open_AI_ATO_2025.pdf"
    width="100%"
    height="400px"
    style="border:none;"
    >
    </iframe>
```

```{python}
#| echo: false
#| output: false
import pandas as pd
# ==== LOAD CSV DATA ====   

open_df = pd.read_csv('model_data/primary_datasets/hf_models_open_raw.csv')

open_source_df = pd.read_csv('model_data/primary_datasets/hf_models_open_source_raw.csv')
```


## 2.0 Licensing Environment
Two OSI-approved Open Source licenses––Apache 2.0 and MIT––are the most popular licenses, accounting for 28% of all models in the sample. A much smaller share (3%) are released under CC-by licenses, despite Creative Commons’ advice against using their licenses for software, as they don’t specify how source code can be distributed.  

A majority of models (58%) are released with an “unknown” license, pointing to a lack of standardization in how data about models is collected and a general lack of enforceability in requiring a license for AI model releases on Hugging Face.

The full list of [OSI-approved licenses are available online](https://opensource.org/licenses).

::: {.callout-tip title="Why this matters"}
This finding suggests that the code component of a significant portion of models are compatible the OSAID.  However, a much larger subset either omits licensing information, use a custom license or apply a license not appropriate for use with software. 
:::

### 2.1 Top 10 Licenses

```{python}
import pandas as pd

# Load your CSV file 
df = pd.read_csv('model_data/primary_datasets/hf_models_open_raw.csv')

# Count occurrences of each license
license_counts = df['license'].value_counts().reset_index()
license_counts.columns = ['license', 'count']

# Calculate proportion
total_models = len(df)
license_counts['proportion_percent'] = round(100*(license_counts['count'] / total_models), 2)

license_counts[:10]
```


<!-- ## Unique Authors -->
```{python}
#| include: false
open_df['author'].nunique()
#4642

# open_source_df['author'].nunique()
# #31
```

### 2.2 License use over time
```{python}
import pandas as pd
import matplotlib.pyplot as plt

def plot_license_trends(
    df: pd.DataFrame,
    date_col: str = "date_released",
    license_col: str = "license",
    licenses_to_include: list = None,
    freq: str = "M",   # 'M' for month, 'Y' for year
    top_n: int = None,
    kind: str = "line",
    figsize=(12,6)
):
    """
    Plots how selected licenses are used over time.

    Parameters
    ----------
    df : pd.DataFrame
        Input DataFrame.
    date_col : str
        Name of the column with dates (e.g. 'created_at' or 'last_modified').
    license_col : str
        Name of the column with license names.
    licenses_to_include : list, optional
        A list of license names to include (e.g. ['mit', 'apache-2.0']).
        If None, all non-unknown licenses are used.
    freq : str, default='M'
        Time frequency for aggregation ('M' for month, 'Y' for year).
    top_n : int, optional
        If provided, only the top N most frequent licenses are plotted.
    kind : str, default='line'
        'line' or 'area' chart type.
    figsize : tuple, default=(12,6)
        Figure size for the plot.
    """

    # 1️⃣ Convert to datetime
    df = df.copy()
    df[date_col] = pd.to_datetime(df[date_col], errors="coerce")

    # 2️⃣ Clean up licenses
    df[license_col] = df[license_col].astype(str).str.strip().str.lower()
    df = df[df[license_col].notna() & (df[license_col] != "unknown")]

    # 3️⃣ Filter for licenses of interest
    if licenses_to_include:
        licenses = [l.lower() for l in licenses_to_include]
        df = df[df[license_col].isin(licenses)]

    # 4️⃣ Create period column (e.g., year-month)
    df["period"] = df[date_col].dt.to_period(freq).astype(str)

    # 5️⃣ Group and pivot
    grouped = (
        df.groupby(["period", license_col])
        .size()
        .reset_index(name="count")
    )

    pivoted = grouped.pivot(
        index="period", columns=license_col, values="count"
    ).fillna(0)

    # 6️⃣ Sort by date
    pivoted.index = pd.to_datetime(pivoted.index)
    pivoted = pivoted.sort_index()

    # 7️⃣ Optionally select top N
    if top_n:
        top_cols = pivoted.sum().sort_values(ascending=False).head(top_n).index
        pivoted = pivoted[top_cols]

    # 8️⃣ Plot
    plt.figure(figsize=figsize)

    if kind == "area":
        pivoted.plot.area(figsize=figsize, alpha=0.8)
    else:
        pivoted.plot(kind="line", linewidth=2, figsize=figsize)

    plt.title("License Usage Over Time")
    plt.xlabel("Date")
    plt.ylabel("Number of Models")
    plt.legend(title="License", bbox_to_anchor=(1.05, 1), loc="upper left")
    plt.tight_layout()
    plt.show()

    return pivoted

```

```{python}
#| warning: false
# Copy original dataframe
df_temp = open_df.copy()

# Drop rows with missing licenses
df_temp = df_temp[df_temp['license'].notna()].copy()

# Normalize licenses (lowercase and remove spaces)
df_temp['license'] = df_temp['license'].astype(str).str.lower().str.strip()

# Combine all licenses that contain 'llama' into one label
df_temp['license_combined'] = df_temp['license'].apply(
    lambda x: 'llama-family' if 'llama' in x else x
)

# Optional: check results
# print(f"Rows kept: {len(df_temp)}")

# df_temp['license_combined'].value_counts().head(10)

## Plot the top 5 licenses over time
plot_license_trends(
    df=df_temp,
    date_col="date_released",
    license_col="license_combined",
    freq="M",
    top_n=5,
    figsize=(8,5)
)


```



### 2.3 Licenses by author
```{python}
#| warnings: false
# --- Config (edit these) ---
CSV_PATH   = "hf_models_by_author.csv"   # your existing CSV with model rows
OUT_DIR    = "authors/author_license_counts"    # where to save outputs
AUTHOR_COL = "owner"                              # column name for author/owner
LICENSE_COL= "license"                             # column name for license string
ID_COL     = "repo_id"                                  # optional: unique model id to drop dups (set None to skip)
# ---------------------------

import os, re
import pandas as pd
from pathlib import Path

Path(OUT_DIR).mkdir(parents=True, exist_ok=True)

# Load
df = pd.read_csv(CSV_PATH)

# Optional: drop duplicates by model id if your CSV may have repeats
if ID_COL and ID_COL in df.columns:
    df = df.drop_duplicates(subset=[ID_COL])

# Keep only needed columns; guard missing cols
missing = [c for c in [AUTHOR_COL, LICENSE_COL] if c not in df.columns]
if missing:
    raise ValueError(f"Missing required columns in CSV: {missing}")

work = df[[AUTHOR_COL, LICENSE_COL]].copy()

# Normalize author
work[AUTHOR_COL] = work[AUTHOR_COL].fillna("").astype(str).str.strip()
work.loc[work[AUTHOR_COL] == "", AUTHOR_COL] = "UNKNOWN_AUTHOR"

# Normalize and split license strings:
# - lower case
# - replace separators (comma/semicolon/slash/pipe) with commas
# - remove extra spaces
# - split into multiple rows (explode)
def normalize_license(s: str) -> str:
    s = (s or "").strip()
    if not s:
        return "unknown"
    s = s.lower()
    # common synonyms/variants
    synonyms = {
        "apache2": "apache-2.0",
        "apache 2.0": "apache-2.0",
        "apache-2": "apache-2.0",
        "mit license": "mit",
        "bsd-3": "bsd-3-clause",
        "bsd-3-clause license": "bsd-3-clause",
        "cc by 4.0": "cc-by-4.0",
        "cc-by": "cc-by-4.0",
        "cc-by v4": "cc-by-4.0",
        "cc-by-4": "cc-by-4.0",
        "cc-by 4.0": "cc-by-4.0",
        "creative commons attribution 4.0": "cc-by-4.0",
        "proprietary license": "proprietary",
        "unknown license": "unknown",
    }
    s = synonyms.get(s, s)
    return s

# Replace various separators with commas, then split
sep_pattern = re.compile(r"[;,/|]+")
work[LICENSE_COL] = (
    work[LICENSE_COL]
    .fillna("unknown")
    .astype(str)
    .str.replace(r"\s+", " ", regex=True)
    .str.strip()
    .str.replace(sep_pattern, ",", regex=True)
)

# Split and explode to one license per row
work = (
    work
    .assign(**{LICENSE_COL: work[LICENSE_COL].str.split(",")})
    .explode(LICENSE_COL, ignore_index=True)
)

# Final clean of license tokens
work[LICENSE_COL] = (
    work[LICENSE_COL]
    .astype(str)
    .str.strip()
    .pipe(lambda s: s.where(s != "", "unknown"))
    .map(normalize_license)
)

# TALL: counts per author x license
counts_tall = (
    work
    .groupby([AUTHOR_COL, LICENSE_COL], dropna=False)
    .size()
    .reset_index(name="count")
    .sort_values([AUTHOR_COL, "count"], ascending=[True, False])
)

# WIDE: pivot to one row per author with license columns
counts_wide = (
    counts_tall
    .pivot(index=AUTHOR_COL, columns=LICENSE_COL, values="count")
    .fillna(0)
    .astype(int)
    .sort_index()
)
counts_wide["TOTAL"] = counts_wide.sum(axis=1)
counts_wide = counts_wide.sort_values("TOTAL", ascending=False)

# Save
tall_path = Path(OUT_DIR) / "author_license_counts_tall.csv"
wide_path = Path(OUT_DIR) / "author_license_counts_wide.csv"
counts_tall.to_csv(tall_path, index=False)
counts_wide.to_csv(wide_path)

# Preview
# print(f"Saved:\n  {tall_path}\n  {wide_path}")
display(counts_tall.head(20))
display(counts_wide.head(20))
```

### 2.4 Custom Licenses
Custom licenses like Qwen, Llama, Gemma, Grok, and OpenRAIL are becoming increasingly common, particularly among for large foundation models. Most, if not all, proprietary licenses impose usage restrictions that appear incompatible with the four freedoms of Open Source by limiting the domain and purpose of the system’s use.

::: {.callout-tip title="Why this matters"}
This trend reflects a growing prevalence of “open washing,” in which developers gain the reputational and adoption benefits associated with Open Source software while simultaneously restricting model use and redistributing liability.
:::


## 3.0 Popular Models & Their Licenses
Many models are built using other, larger models. Greater understanding of the terms under which these large models are released will be instrumental as we look further into how developers use and interpret the OSAID and Open Source AI.  

::: {.callout-tip title="Why this matters?"}
The licensing and AI model publishing practices among popularly-used models will likely have greater downstream influence. 
::: 

### 3.1 Top 10 Most Popular Models
While the sample has over 20,000 models, many use other "base models" which are result in smaller models that are [fine-tuned](https://huggingface.co/docs/transformers/training) or [quantized](https://huggingface.co/docs/optimum/en/concept_guides/quantization) versions of the larger base model.


```{python}

popular_models_df = pd.read_csv('model_genealogy/most_popular_models_v2.csv')

# popular_models_df.head(20)
display_popular_models = popular_models_df[['model_name', 'num_children']] \
    .head(10) \
    .rename(columns={
        'model_name': 'Model Name',
        'num_children': 'Children Count'
    })

display_popular_models


```

### 3.2 Popular Models' Licenses
At the organization level, licensing practices are surprisingly homogeneous. First, all organizations in this study, except for OpenAI, have models that use a proprietary (i.e. custom) license as well as models that use OSI-approved Open Source licenses. 

In general, the organizations are released their largest, flagship 'open' model under a restrictive, customized license while smaller or older models are released under permissive or standard Open Source licenses. 

::: {.callout-tip title="Why this matters?"}
Every custom license (.e.g Llama, Qwen) in this study uses the language of Open Source, including permissions to use, study, share and modify the system while at the same time imposing restrictions on how or where a system is used. Often, usage restrictions are subject to Acceptable Use Policies akin to consumer apps and services. 
:::

| Organization | Number of Models | License Types |
|--------------|------------------|----------------|
| [Alibaba (Qwen)](https://huggingface.co/Qwen) | +300 | Apache 2.0, Qwen |
| [DeepSeek](https://huggingface.co/deepseek-ai) | 78  | MIT for code, DeepSeek for model license |
| [Meta (Llama)](https://huggingface.co/meta-llama) | 70 | Llama-family of licenses |
| [Mistral](https://huggingface.co/mistralai) | 39 | Apache 2.0 |
|[Microsoft](https://huggingface.co/microsoft) | +400 | MIT, Apache, CC BY-*, Microsoft Research License |
| [Google](https://huggingface.co/google) | +1000 | Apache 2.0, Gemma licenses |
| [XAI (Grok)](https://huggingface.co/XAI) | 2 | Grok-1 under Apache 2.0, Grok-2 under Grok-2 license |
| [OpenAI](https://huggingface.co/openai) | 30 | Apache 2.0 |

#### 3.2.1 Qwen 
<details>
<summary>Qwen License Seek Details</summary>
<!--All you need is a blank line-->
2. Grant of Rights
You are granted a non-exclusive, worldwide, non-transferable and royalty-free limited license under Alibaba Cloud's intellectual property or other rights owned by Us embodied in the Materials **to use, reproduce, distribute, copy, create derivative works of, and make modifications to the Materials.**

4. Restrictions
If you are commercially using the Materials, and **your product or service has more than 100 million monthly active users, You shall request a license from Us.** You cannot exercise your rights under this Agreement without our express authorization.
</details>

#### 3.2.2 DeepSeek (Model License)
<details>
<summary>DeepSeek License Details</summary>
<!--All you need is a blank line-->

2. Grant of Copyright License. Subject to the terms and conditions of this License, DeepSeek hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to **reproduce, prepare, publicly display, publicly perform, sublicense, and distribute** the Complementary Material, the Model, and Derivatives of the Model.

***Use Restrictions** You agree not to use the Model or Derivatives of the Model:
In any way that violates any applicable national or international law or regulation or infringes upon the lawful rights and interests of any third party;
For military use in any way;
For the purpose of exploiting, harming or attempting to exploit or harm minors in any way;
To generate or disseminate verifiably false information and/or content with the purpose of harming others;
To generate or disseminate inappropriate content subject to applicable regulatory requirements; 
To generate or disseminate personal identifiable information without due authorization or for unreasonable use;
To defame, disparage or otherwise harass others;
For fully automated decision making that adversely impacts an individual’s legal rights or otherwise creates or modifies a binding, enforceable obligation;
For any use intended to or which has the effect of discriminating against or harming individuals or groups based on online or offline social behavior or known or predicted personal or personality characteristics;
To exploit any of the vulnerabilities of a specific group of persons based on their age, social, physical or mental characteristics, in order to materially distort the behavior of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm;
For any use intended to or which has the effect of discriminating against individuals or groups based on legally protected characteristics or categories.
</details>




#### 3.2.2 Llama
<details>
<summary>Llama License Details</summary>
<!--All you need is a blank line-->

a. Grant of Rights. You are granted a non-exclusive, worldwide, non-transferable and royalty-free limited license under Meta’s intellectual property…**to use, reproduce, distribute, copy, create derivative works of, and make modifications to the Llama Materials.**

iv. Your use of the Llama Materials must…***adhere to the Acceptable Use Policy** for the Llama Materials (available at https://llama.com/llama3/use-policy), which is hereby incorporated by reference into this Agreement.

2. Additional Commercial Terms. If, on the Meta Llama 3 version release date, the monthly active users of the products or services made… is greater than **700 million monthly active users in the preceding calendar month, you must request a license from Meta…**

With respect to any multimodal models included in Llama 4, the rights granted under Section 1(a) of the Llama 4 Community License Agreement are **not being granted to you if you are an individual domiciled in, or a company with a principal place of business in, the European Union.**
</details>

#### 3.2.3 Grok
<details>
<summary>Grok License Details</summary>
<!--All you need is a blank line-->

a. Permitted Uses: xAI grants you a non-exclusive, worldwide, revocable license to **use, reproduce, distribute, and modify the Materials: For non-commercial and research purposes; and for commercial use solely if you and your affiliates abide by all of the guardrails provided in xAI's Acceptable Use Policy (https://x.ai/legal/acceptable-use-policy),** including 1. Comply with the law, 2. Do not harm people or property, and 3. Respect guardrails and don't mislead.

b. Restrictions:
You may not use the Materials, derivatives, or outputs (including generated data) to **train, create, or improve any foundational, large language, or general-purpose AI models,** except for modifications or fine-tuning of Grok 2 permitted under and in accordance with the terms of this Agreement.

5. Acceptable Use
**You are responsible for implementing appropriate safety measures, including filters and human oversight, suitable for your use case. You must comply with xAI’s Acceptable Use Policy (AUP), as well as all applicable laws. You may not use the Materials for illegal, harmful, or abusive activities.**
</details>

#### 3.2.4 Gemma 
<details>
<summary>Gemma License Details</summary>
<!--All you need is a blank line-->

2.2 Use
You may **use, reproduce, modify, Distribute, perform or display** any of the Gemma Services only in accordance with the terms of this Agreement, and must not violate (or encourage or permit anyone else to violate) any term of this Agreement.

3.2 Use Restrictions
You **must not use any of the Gemma Services: for the restricted uses set forth in the Gemma Prohibited Use Policy at ai.google.dev/gemma/prohibited_use_policy ("Prohibited Use Policy"),** which is hereby incorporated by reference into this Agreement; or in violation of applicable laws and regulations.
</details>


## 4.0 Conclusion & Next Steps
Collectively, these preliminary findings start to delineate the gaps between rhetoric and reality in "open" AI development. Most importantly, early results underscore a deep chasm between how openness is signaled and the OSAID. 

Moving forward, the next phase of the analysis will expand on quantitative findings with further trend and network analysis. For the qualitative portion, quantitative findings will be integrated with assessments on definitions of Open Source AI in federal and state policy documents. 

> This is a living project, and I’m eager to collaborate.

I plan to extend this study by:

- Conducting network analysis of model relationships and building a model genealogy.
- Tracking license propagation to see if restrictions are spreading correctly or being ignored.
- Analyzing download and reuse trends to measure real-world impact.
- Studying documentation practices and how developers describe openness.
- Connecting these findings to policy frameworks, since future AI legislation will hinge on how “open source AI” is defined and applied.