{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3c3b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "try:\n",
    "    import yaml  # pip install pyyaml\n",
    "except Exception:\n",
    "    yaml = None\n",
    "\n",
    "def _normalize_license(val):\n",
    "    \"\"\"Return a clean license string from various shapes.\"\"\"\n",
    "    if val is None:\n",
    "        return \"\"\n",
    "    if isinstance(val, str):\n",
    "        return val.strip()\n",
    "    if isinstance(val, (list, tuple)):\n",
    "        uniq = [str(s).strip() for s in val if s and str(s).strip()]\n",
    "        return \", \".join(sorted(set(uniq)))\n",
    "    if isinstance(val, dict):\n",
    "        for k in (\"id\", \"name\", \"license\", \"value\"):\n",
    "            if k in val and val[k]:\n",
    "                return str(val[k]).strip()\n",
    "        try:\n",
    "            import json\n",
    "            return json.dumps(val, ensure_ascii=False)\n",
    "        except Exception:\n",
    "            return str(val)\n",
    "    return str(val).strip()\n",
    "\n",
    "def _parse_yaml_front_matter(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse YAML front-matter from README markdown text.\n",
    "    Supports:\n",
    "      ---\\n<yaml>\\n---   or\n",
    "      ---\\n<yaml>\\n...\n",
    "    Returns {} if not found or parse fails.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return {}\n",
    "    # Match front matter at the very top of the file\n",
    "    m = re.match(r\"^\\s*---\\s*\\n(.*?)\\n(?:---|\\.\\.\\.)\\s*(?:\\n|$)\", text, re.DOTALL)\n",
    "    if not m:\n",
    "        return {}\n",
    "    yaml_block = m.group(1)\n",
    "    # Prefer PyYAML if present\n",
    "    if yaml is not None:\n",
    "        try:\n",
    "            data = yaml.safe_load(yaml_block) or {}\n",
    "            if isinstance(data, dict):\n",
    "                return data\n",
    "            return {}\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Minimal fallback: parse simple key: value and lists with \"- item\"\n",
    "    data = {}\n",
    "    current_key = None\n",
    "    for line in yaml_block.splitlines():\n",
    "        if re.match(r\"^\\s*#\", line) or not line.strip():\n",
    "            continue\n",
    "        kv = re.match(r\"^([A-Za-z0-9_\\-]+)\\s*:\\s*(.*)$\", line)\n",
    "        if kv:\n",
    "            key, value = kv.group(1), kv.group(2).strip()\n",
    "            if value == \"\" or value == \"|\":\n",
    "                data[key] = []\n",
    "                current_key = key\n",
    "            elif value.startswith(\"[\") and value.endswith(\"]\"):\n",
    "                # simple inline list: [a, b]\n",
    "                items = [s.strip() for s in value[1:-1].split(\",\") if s.strip()]\n",
    "                data[key] = items\n",
    "                current_key = None\n",
    "            else:\n",
    "                data[key] = value\n",
    "                current_key = None\n",
    "            continue\n",
    "        # list item\n",
    "        if current_key and re.match(r\"^\\s*-\\s+\", line):\n",
    "            item = re.sub(r\"^\\s*-\\s+\", \"\", line).strip()\n",
    "            data.setdefault(current_key, [])\n",
    "            data[current_key].append(item)\n",
    "    return data\n",
    "\n",
    "def resolve_license(info, fallback_tags=None, readme_text: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    Resolve license using multiple sources, in order:\n",
    "      1) info.cardData (license, licenses, license_name, license_id)\n",
    "      2) info.config.license\n",
    "      3) tags entries like 'license:apache-2.0'\n",
    "      4) README YAML front-matter keys: license, licenses, license_name, license_id\n",
    "      5) presence of LICENSE file (returns 'license-file' if found)\n",
    "    Also returns an optional license_link if present in YAML (e.g., 'license_link').\n",
    "    \"\"\"\n",
    "    # 1) cardData\n",
    "    cd = getattr(info, \"cardData\", None)\n",
    "    if isinstance(cd, dict):\n",
    "        for key in (\"license\", \"licenses\", \"license_name\", \"license_id\"):\n",
    "            if key in cd and cd[key]:\n",
    "                lic = _normalize_license(cd[key])\n",
    "                if lic:\n",
    "                    return lic, cd.get(\"license_link\", \"\")\n",
    "\n",
    "    # 2) config\n",
    "    cfg = getattr(info, \"config\", None)\n",
    "    if isinstance(cfg, dict) and cfg.get(\"license\"):\n",
    "        lic = _normalize_license(cfg[\"license\"])\n",
    "        if lic:\n",
    "            return lic, \"\"\n",
    "\n",
    "    # 3) tags (handles the common 'license:apache-2.0' pattern)\n",
    "    tags = fallback_tags or getattr(info, \"tags\", None)\n",
    "    if tags:\n",
    "        for t in tags:\n",
    "            if isinstance(t, str) and t.lower().startswith(\"license:\"):\n",
    "                lic = t.split(\":\", 1)[1].strip()\n",
    "                if lic:\n",
    "                    return lic, \"\"\n",
    "\n",
    "    # 4) README YAML front-matter\n",
    "    if readme_text:\n",
    "        meta = _parse_yaml_front_matter(readme_text)\n",
    "        if meta:\n",
    "            for key in (\"license\", \"licenses\", \"license_name\", \"license_id\"):\n",
    "                if key in meta and meta[key]:\n",
    "                    lic = _normalize_license(meta[key])\n",
    "                    link = _normalize_license(meta.get(\"license_link\", \"\"))\n",
    "                    if lic:\n",
    "                        return lic, link\n",
    "\n",
    "    # 5) LICENSE file present?\n",
    "    try:\n",
    "        siblings = getattr(info, \"siblings\", None) or []\n",
    "        has_license_file = any(\n",
    "            hasattr(s, \"rfilename\") and s.rfilename.upper() == \"LICENSE\" for s in siblings\n",
    "        )\n",
    "        if has_license_file:\n",
    "            return \"license-file\", \"\"\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return \"\", \"\"  # unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b332ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "base_model: Qwen/Qwen2.5-7B-Instruct\n",
      "library_name: transformers\n",
      "model_name: openthoughts3_math_teachers_source_split_17000_20000_0_qwen2_5_7b_instruct\n",
      "tags:\n",
      "- generated_from_trainer\n",
      "- trl\n",
      "- sft\n",
      "licence: license\n",
      "---\n",
      "\n",
      "# Model Card for openthoughts3_math_teachers_source_split_17000_20000_0_qwen2_5_7b_instruct\n",
      "\n",
      "This model is a fine-tuned version of [Qwen/Qwen2.5-7B-Instruct](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct).\n",
      "It has been trained using [TRL](https://github.com/huggingface/trl).\n",
      "\n",
      "## Quick start\n",
      "\n",
      "```python\n",
      "from transformers import pipeline\n",
      "\n",
      "question = \"If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?\"\n",
      "generator = pipeline(\"text-generation\", model=\"None\", device=\"cuda\")\n",
      "output = generator([{\"role\": \"user\", \"content\": question}], max_new_tokens=128, return_full_text=False)[0]\n",
      "print(output[\"generated_text\"])\n",
      "```\n",
      "\n",
      "## Training procedure\n",
      "\n",
      "[<img src=\"https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg\" alt=\"Visualize in Weights & Biases\" width=\"150\" height=\"24\"/>](https://wandb.ai/chenwu/huggingface/runs/0lle1p9p) \n",
      "\n",
      "\n",
      "This model was trained with SFT.\n",
      "\n",
      "### Framework versions\n",
      "\n",
      "- TRL: 0.19.1\n",
      "- Transformers: 4.51.1\n",
      "- Pytorch: 2.7.0\n",
      "- Datasets: 4.0.0\n",
      "- Tokenizers: 0.21.4\n",
      "\n",
      "## Citations\n",
      "\n",
      "\n",
      "\n",
      "Cite TRL as:\n",
      "    \n",
      "```bibtex\n",
      "@misc{vonwerra2022trl,\n",
      "\ttitle        = {{TRL: Transformer Reinforcement Learning}},\n",
      "\tauthor       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallou{\\'e}dec},\n",
      "\tyear         = 2020,\n",
      "\tjournal      = {GitHub repository},\n",
      "\tpublisher    = {GitHub},\n",
      "\thowpublished = {\\url{https://github.com/huggingface/trl}}\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import model_info, hf_hub_download, HfApi\n",
    "from huggingface_hub.utils import HfHubHTTPError\n",
    "\n",
    "repo_id = \"ChenWu98/openthoughts3_math_teachers_source_split_17000_20000_0_qwen2_5_7b_instruct\"\n",
    "\n",
    "# If the repo is private/gated, set your token here or in HF_TOKEN env var\n",
    "api = HfApi()  # or HfApi(token=\"hf_xxx\")\n",
    "\n",
    "info = model_info(repo_id)  # HEAD of default branch (usually 'main')\n",
    "print(\"Default branch head SHA:\", info.sha)\n",
    "print(\"Last modified:\", info.lastModified)\n",
    "\n",
    "try:\n",
    "    readme_path = hf_hub_download(\n",
    "        repo_id=repo_id,\n",
    "        filename=\"README.md\",\n",
    "        repo_type=\"model\",\n",
    "        revision=info.sha,           # pin to exactly what the page shows\n",
    "        force_download=True,         # bypass local cache\n",
    "        local_files_only=False\n",
    "    )\n",
    "    with open(readme_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        readme_text = f.read()\n",
    "    print(readme_text[:500])  # sanity check\n",
    "except HfHubHTTPError as e:\n",
    "    print(\"Failed to download README:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
